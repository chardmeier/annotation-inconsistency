def match_all_mentions2(enChains, deChains, alignedChains, entext, detext):
    """
    :param src_aligns: {111 {'set_257': {1: [16]}, 'set_258': {0: [9], 1: [10, 11], 2: []}} --> here there can be [] if word is not aligned
    :param tgt_links: {1134 {'set_288': {1: [19], 2: [29], 8: [13]}, 'set_289': {2: [2]}}
    :return: (dic, dic, dic, dic)
    """

    matches = {}
    partial = {}
    missing = {}
    de_not_in_en = {}
    en_not_in_de = {}

    for i in range(len(entext)):
        print(entext[i])
        if i >= len(detext):
            print("problem with sentence splitting annotation in this document")
            print(detext[i-1])
        else:
            print(detext[i])

        if i in enChains:# enChains and alignedChains have the same keys

            only_in_en = []
            if i not in deChains:
                for chain in enChains[i]:
                    only_in_en += enChains[i][chain].values()
                en_not_in_de[i] = only_in_en

                onlyEN = put_into_words(only_in_en, entext[i])
                print("==> Mentions not annotated in German")
                print(onlyEN)
                print("\n")

            else:
                mentions_in_enlish = []
                mentions_in_german = []
                alignments_of_english = []

                for chain in enChains[i]:
                    mentions_in_enlish += enChains[i][chain].values()

                for chain in alignedChains[i]:
                    alignments_of_english += alignedChains[i][chain].values()

                for chain in deChains[i]:
                    mentions_in_german += deChains[i][chain].values()

                # translated positions into words
                en_chains = put_into_words(mentions_in_enlish, entext[i])
                al_chains = put_into_words(alignments_of_english, detext[i])
                de_chains = put_into_words(mentions_in_german, detext[i])

                x = [x in mentions_in_enlish for x in mentions_in_german]
                # easy case: all mentions in the chain match
                if False not in set(x):
                    matches[i] = mentions_in_german
                    print("==All EN mentions in DE:")
                    print("==english=====>", en_chains)
                    print("==aligned_to==>", al_chains)
                    print("==german======>", de_chains)
                    print("\n")

                # some mention matches
                elif (True in set(x)) and (False in set(x)):
                    partial[i] = mentions_in_german

                    print("==Some EN mentions in DE:")
                    print("==english=====>", en_chains)
                    print("==aligned_to==>", al_chains)
                    print("==german======>", de_chains)
                    print("\n")

                # none mention matches
                else:
                    missing[i] = mentions_in_german

                    print("==None EN mentions in DE:")
                    print("==english=====>", en_chains)
                    print("==aligned_to==>", al_chains)
                    print("==german======>", de_chains)
                    print("\n")

        elif i in deChains:
            only_in_de = []
            if i not in enChains:
                for chain in deChains[i]:
                    only_in_de += deChains[i][chain].values()
                de_not_in_en[i] = only_in_de
            onlyDE = put_into_words(only_in_de, detext[i])
            print("==> Mentions not annotated in German")
            print(onlyDE)
            print("\n")
        else:
            print("==> Unannotated sentence pair")
            print("\n")


    # for sent in deChains:
    #     only_in_de = []
    #     if sent not in enChains:
    #         for chain in deChains[sent]:
    #             only_in_de += deChains[sent][chain].values()
    #         de_not_in_en[sent] = only_in_de
    #     onlyDE = put_into_words(only_in_de, detext[sent])
    #     print("==> Mentions not annotated in English")
    #     print(onlyDE)
    #     print("\n")

    return matches, partial, missing, de_not_in_en, en_not_in_de



def match_all_mentions2(enChains, deChains, alignedChains, entext, detext):
    """
    :param src_aligns: {111 {'set_257': {1: [16]}, 'set_258': {0: [9], 1: [10, 11], 2: []}} --> here there can be [] if word is not aligned
    :param tgt_links: {1134 {'set_288': {1: [19], 2: [29], 8: [13]}, 'set_289': {2: [2]}}
    :return: (dic, dic, dic, dic)
    """

    matches = {}
    partial = {}
    missing = {}
    de_not_in_en = {}
    en_not_in_de = {}

    for i in range(len(entext)):
        print(entext[i])
        print(detext[i])

        if i in enChains:

            for sent in enChains: # enChains and alignedChains have the same keys
                only_in_en = []
                if sent not in deChains:
                    for chain in enChains[sent]:
                        only_in_en += enChains[sent][chain].values()
                    en_not_in_de[sent] = only_in_en

                    onlyEN = put_into_words(only_in_en, entext[sent])
                    print("==> Mentions not annotated in German")
                    print(onlyEN)
                    print("\n")

                else:
                    mentions_in_enlish = []
                    mentions_in_german = []
                    alignments_of_english = []

                    for chain in enChains[sent]:
                        mentions_in_enlish += enChains[sent][chain].values()

                    for chain in alignedChains[sent]:
                        alignments_of_english += alignedChains[sent][chain].values()

                    for chain in deChains[sent]:
                        mentions_in_german += deChains[sent][chain].values()

                    # translated positions into words
                    en_chains = put_into_words(mentions_in_enlish, entext[sent])
                    al_chains = put_into_words(alignments_of_english, detext[sent])
                    de_chains = put_into_words(mentions_in_german, detext[sent])

                    x = [x in mentions_in_enlish for x in mentions_in_german]
                    # easy case: all mentions in the chain match
                    if False not in set(x):
                        matches[sent] = mentions_in_german
                        print("==All EN mentions in DE:")
                        print("==english=====>", en_chains)
                        print("==aligned_to==>", al_chains)
                        print("==german======>", de_chains)
                        print("\n")

                    # some mention matches
                    elif (True in set(x)) and (False in set(x)):
                        partial[sent] = mentions_in_german

                        print("==Some EN mentions in DE:")
                        print("==english=====>", en_chains)
                        print("==aligned_to==>", al_chains)
                        print("==german======>", de_chains)
                        print("\n")

                    # none mention matches
                    else:
                        missing[sent] = mentions_in_german

                        print("==None EN mentions in DE:")
                        print("==english=====>", en_chains)
                        print("==aligned_to==>", al_chains)
                        print("==german======>", de_chains)
                        print("\n")
        else:
            for sent in deChains:
                only_in_de = []
                if sent not in enChains:
                    for chain in deChains[sent]:
                        only_in_de += deChains[sent][chain].values()
                    de_not_in_en[sent] = only_in_de
                onlyDE = put_into_words(only_in_de, detext[sent])
                print("==> Mentions not annotated in English")
                print(onlyDE)
                print("\n")

    return matches, partial, missing, de_not_in_en, en_not_in_de




















def match_all_mentions(en, src_aligns, tgt_links):
    """
    :param src_aligns: {111 {'set_257': {1: [16]}, 'set_258': {0: [9], 1: [10, 11], 2: []}} --> here there can be [] if word is not aligned
    :param tgt_links: {1134 {'set_288': {1: [19], 2: [29], 8: [13]}, 'set_289': {2: [2]}}
    :return: (dic, dic, dic, dic)
    """

    all_matches = {}
    all_partial = {}
    all_missing = {}
    all_missing_source = {}

    # source chains not annotated in target
    for sentence in src_aligns:
        if key not in tgt_links:
            all_missing_source[sentence] = en[sentence]

    #easy case
    for sentence in tgt_links:
        matches = {}
        partial = {}
        missing = {}
        if sentence in src_aligns:
            for chain_t in tgt_links[sentence]:
                # loop through all chains in src_aligned
                for chain_a in src_aligns[sentence]:
                    x = [x in src_aligns[sentence][chain_a] for x in tgt_links[sentence][chain_t]]
                    # easy case: all mentions in the chain match
                    if False not in set(x):
                        matches[chain_t] = tgt_links[sentence][chain_t]
                    # some mention matches
                    elif (True in set(x)) and (False in set(x)):
                        partial[chain_t] = tgt_links[sentence][chain_t]
                    # none mention matches
                    else:
                        if find_partial(tgt_links[sentence][chain_t], src_aligns[key]):
                            partial[chain_t] = tgt_links[sentence][chain_t]
                        else:
                            missing[chain_t] = tgt_links[sentence][chain_t]
            if matches != {}:
                all_matches[key] = matches
            if partial != {}:
                all_partial[key] = partial
            if missing != {}:
                all_missing[key] = missing
        else:
            all_missing[key] = tgt_links[key]

    #(PRINT sanity check
    #
    # print("\n")
    # total_matches = 0
    # for key in all_matches:
    #     for chain in all_matches[key]:
    #         for mention in all_matches[key][chain]:
    #             total_matches += len(mention)
    #     #print (key, all_matches[key])
    # print("complete match ===>", total_matches)
    #
    # total_partial = 0
    # for key in all_partial:
    #     for chain in all_partial[key]:
    #         for mention in all_partial[key][chain]:
    #             total_partial += len(mention)
    #     #print(key, all_partial[key])
    # print("partial match ===>", total_partial)
    #
    # total_missing = 0
    # for key in all_missing:
    #     for chain in all_missing[key]:
    #         for mention in all_missing[key][chain]:
    #             total_missing += len(mention)
    #     #print(key, all_missing[key])
    # print("target words missing in source ===>", total_missing)
    #
    # source_not_in_target = 0
    # for key in all_missing_source:
    #     for chain in all_missing_source[key]:
    #         for mention in all_missing_source[key][chain]:
    #             source_not_in_target += len(mention)
    # print("source words missing in target ===>", source_not_in_target)
    #
    # total_mentions = total_matches + total_missing + total_partial
    # print("total words classified in doc==> ", total_mentions)
    #)

    return all_matches, all_partial, all_missing, all_missing_source



















def prettify_chains(chains, text):

    sentence = text.split()
    prettified = {}

    for chain in chains:
        pretty_chain = []
        for mention in chains[chain]:
            pretty_mention = []
            for word in mention:
                if word < len(sentence):
                    pretty_mention.append(sentence[word])
                #else:
                #    print("indexing error") #"weird case", word, sentence, len(sentence))
            pretty_chain.append(" ".join(pretty_mention))
        prettified[chain] = pretty_chain

    return prettified


def print_out(english_chains, german_chains, aligned_chains, matched_chains):

    ordered_en=sorted(english_chains.keys())
    ordered_de=sorted(german_chains.keys())
    ordered_mat=sorted(matched_chains.keys())
    ordered_alg=sorted(aligned_chains.keys())

    print(" ==> english mentions in sentence:")
    for j in range(len(ordered_en)):
        print(ordered_en[j], english_chains[ordered_en[j]])

    print(" ==> alignments points of english:")

    for j in range(len(ordered_alg)):
        print(ordered_alg[j], aligned_chains[ordered_alg[j]])

    print(" ==> german mentions in sentence:")

    for j in range(len(ordered_de)):
        print(ordered_de[j], german_chains[ordered_de[j]])

    print(" ==> considered german mention in classification:")

    for j in range(len(ordered_mat)):
        print(ordered_mat[j], matched_chains[ordered_mat[j]])






        # for i in range(len(sentence_based_enDoc)):
        #     print("\n")
        #     print(sentence_based_enDoc[i])
        #     print(sentence_based_deDoc[i])
        #     print("\n")
        #     if i in matches:
        #         print(" ==> ALL MENTIONS MATCH ")
        #         relevant = prettify_chains(matches[i], sentence_based_deDoc[i])
        #         english = prettify_chains(en_sents_wrt_en_chains[i], sentence_based_enDoc[i])
        #         german = prettify_chains(de_sents_wrt_de_chains[i], sentence_based_deDoc[i])
        #         aligned = prettify_chains(align_of_en_chains[i], sentence_based_deDoc[i])
        #
        #         print_out(english, german, aligned, relevant)
        #
        #         print("\n")
        #
        #     elif i in missing_tgt:
        #         print(" ==> GERMAN MENTIONS NOT IN ENGLISH")
        #         relevant = prettify_chains(missing_tgt[i], sentence_based_deDoc[i])
        #         german = prettify_chains(de_sents_wrt_de_chains[i], sentence_based_deDoc[i])
        #         if i in en_sents_wrt_en_chains:
        #             english = prettify_chains(en_sents_wrt_en_chains[i], sentence_based_enDoc[i])
        #             aligned = prettify_chains(align_of_en_chains[i], sentence_based_deDoc[i])
        #         else:
        #             english = {}
        #             aligned = {}
        #         print_out(english, german, aligned, relevant)
        #
        #         print("\n")
        #
        #     elif i in missing_src:
        #         print(" ==> ENGLISH MENTIONS NOT IN GERMAN")
        #         relevant = prettify_chains(missing_src[i], sentence_based_enDoc[i])
        #         english = prettify_chains(en_sents_wrt_en_chains[i], sentence_based_enDoc[i])
        #         aligned = prettify_chains(align_of_en_chains[i], sentence_based_deDoc[i])
        #         if i in de_sents_wrt_de_chains:
        #             german = prettify_chains(de_sents_wrt_de_chains[i], sentence_based_deDoc[i])
        #         else:
        #             german = {}
        #
        #         print_out(english, german, aligned, relevant)
        #
        #         print("\n")
        #
        #     elif i in partial:
        #         print(" ==> PARTIAL MATCHES: ONLY SOME MENTIONS MATCH or SOME TOKENS IN MENTION MATCH")
        #         relevant = prettify_chains(partial[i], sentence_based_deDoc[i])
        #         english = prettify_chains(en_sents_wrt_en_chains[i], sentence_based_enDoc[i])
        #         german = prettify_chains(de_sents_wrt_de_chains[i], sentence_based_deDoc[i])
        #         aligned = prettify_chains(align_of_en_chains[i], sentence_based_deDoc[i])
        #
        #         print_out(english, german, aligned, relevant)
        #
        #         print("\n")
        #
        #     else:
        #         print(" ==> NOT ANNOTATED SENTENCE PAIR")
        #         print("\n")